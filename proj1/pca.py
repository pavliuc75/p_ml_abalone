# -*- coding: utf-8 -*-
"""PCA Project 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1afZCxsPcpEm4LDuk4XxIf6fscvG1yuub
"""

# author - Jai Murhekar (s237013)
#!pip install ucimlrepo

"""Fetching Dataset"""

from ucimlrepo import fetch_ucirepo
import importlib_resources
import numpy as np
import xlrd
import seaborn as sns
import pandas as pd

# fetch dataset
abalone = fetch_ucirepo(id=1)

# data (as pandas dataframes)
features = abalone.data.features
targets = abalone.data.targets

# metadata
metadata = abalone.metadata
print(abalone.metadata)

# variable information
print(abalone.variables)

# Variable information
variables = abalone.variables
print(variables)

"""Dimensions of Dataset"""

classNames = sorted(set(targets['Rings']))
X = features.drop('Sex', axis=1)

N = len(targets)
M = X.shape[1]
C = len(classNames)

print(N)
print(M)
print(C)

"""Standardization of Data"""

import matplotlib.pyplot as plt
from scipy.linalg import svd
import numpy as np

#normalizing the data
mean = np.mean(X, axis=0)

X_centered = X - mean

std_dev = np.std(X_centered, axis=0)

X_normalized = X_centered / std_dev

"""We compute the covariance matrix and plot it as a heatmap. One can see from the figure below that the variables like length, weight etc are highly correlated"""

import numpy as np
import matplotlib.pyplot as plt

# Get feature names from abalone.variables
feature_names = abalone.variables['name'].tolist()[1:8]

# Compute Covariance Matrix
cov_matrix = np.cov(X_normalized.T)  # Transpose X to get features along rows

# Plot Covariance Matrix as Heatmap with annotations
plt.figure(figsize=(8, 6))
heatmap = plt.imshow(cov_matrix, cmap='Reds', interpolation='nearest')  # Use 'Reds' colormap

# Add annotations with covariance values
for i in range(cov_matrix.shape[0]):
    for j in range(cov_matrix.shape[1]):
        plt.text(j, i, f'{cov_matrix[i, j]:.2f}', ha='center', va='center', color='black')

# Add feature names to axes
plt.xticks(ticks=np.arange(len(feature_names)), labels=feature_names, rotation=45)
plt.yticks(ticks=np.arange(len(feature_names)), labels=feature_names)
plt.colorbar(heatmap, label='Covariance')
plt.title('Covariance Matrix (Heatmap)')
plt.xlabel('Feature')
plt.ylabel('Feature')
plt.show()

"""We run PCA and find the amount of variation as a function of the number of components included (scree plot)"""

# PCA by computing SVD of X_normalized
U, S, V = svd(X_normalized, full_matrices=False)

# Compute variance explained by principal components
rho = (S * S) / (S * S).sum()

threshold = 0.9

# Plot variance explained
plt.figure()
plt.plot(range(1, len(rho) + 1), rho, "x-")
plt.plot(range(1, len(rho) + 1), np.cumsum(rho), "o-")
plt.plot([1, len(rho)], [threshold, threshold], "k--")
plt.title("Variance explained by principal components")
plt.xlabel("Principal component")
plt.ylabel("Variance explained")
plt.legend(["Individual", "Cumulative", "Threshold"])
plt.grid()
plt.show()

for i, variance in enumerate(rho):
    print(f"Principal Component {i+1}: Variance Explained = {variance:.2f}")

"""From the plot above, we can see more than 90% of the variation is accounted by the first principal component - this is suggests that the data is highly correlated (which we have already seen earlier). We also output the eigenvectors."""

eigenvals, eigenvecs = np.linalg.eig(cov_matrix)

print("Eigenvals:\n",eigenvals)
print("Eigenvecs corresponding to PC1",eigenvecs[0])

# Compute loadings
loadings = V[0]  # Assuming V contains the principal components from SVD

# Visualize loadings
plt.figure(figsize=(10, 6))
plt.bar(range(len(loadings)), loadings)
plt.xlabel('Feature Index')
plt.ylabel('Loading')
plt.title('Weights of Original Features on PC1/ Principal Directions of PC1 Component')
plt.ylim(0, 1)  # Set the y-axis limit from 0 to 1
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Extract values from the DataFrame column 'targets'
y = targets.values.flatten()

# Project the data onto the principal components
Z = X_normalized @ V.T[:, :1]  # Project onto the first principal component

# Plot the projected data
plt.figure(figsize=(8, 6))
plt.scatter(Z, np.zeros_like(Z), c=y, cmap='jet', alpha=0.5)  # Using 'jet' colormap
plt.xlabel('Principal Component 1')
plt.title('Data Projected onto Principal Component 1')
plt.colorbar(label='Number of Rings')
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Ensure Z is a NumPy array
Z_array = Z.values if isinstance(Z, pd.DataFrame) else Z

# Perform PCA with 2 components
# Adjust the number of components as needed
# Example: Z_2d = X_normalized @ V.T[:, :2]
Z_2d = X_normalized @ V.T[:, :2]

# Plot the projected data
plt.figure(figsize=(8, 6))
plt.scatter(Z_2d.iloc[:, 0], Z_2d.iloc[:, 1], c=y, cmap='tab10', alpha=0.5)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('Data Projected onto First Two Principal Components')
plt.colorbar(label='Class')  # Add a colorbar to show class labels
plt.grid(True)
plt.show()

"""Pairwise Scatter Plot"""

sns.pairplot(X)
plt.show()

diameter = X.iloc[:, 1]  # Use iloc for integer-based indexing
height = X.iloc[:, 2]

# Plot scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(height, diameter, alpha=0.5)
plt.title('Scatter Plot: Diameter vs Height')
plt.xlabel('Height')
plt.ylabel('Diameter')
plt.grid(True)
plt.show()

"""Histograms"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats



for column in X.columns:  # Assuming each column represents a feature
    data = X[column]

    # Plot Histogram
    plt.figure(figsize=(8, 4))
    plt.hist(data, bins=30, color='skyblue', edgecolor='black')
    plt.title(f'Histogram of {column}')
    plt.xlabel('Value')
    plt.ylabel('Frequency')
    plt.show()

import matplotlib.pyplot as plt

# Assuming X is your DataFrame
# Plot Histogram for column with index 1
data = X.iloc[:, 1]

# Plot Histogram
plt.figure(figsize=(8, 4))
plt.hist(data, bins=30, color='skyblue', edgecolor='black')
plt.title(f'Histogram of {X.columns[1]}')
plt.xlabel('Value')
plt.ylabel('Frequency')
plt.show()